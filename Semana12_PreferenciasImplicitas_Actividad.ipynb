{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <img src=\"https://serea2017.uniandes.edu.co/images/Logo.png\" height=\"80\" width=\"150\" align=\"Center\" /> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    "\n",
    "\n",
    "# Sistemas de Recomendación de filtrado colaborativo con preferencias implícitas\n",
    "\n",
    "## Actividad 12\n",
    "\n",
    "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    "\n",
    "## Actividad en grupos\n",
    "### Nombres:     \n",
    "    Arturo Guerrero            (201823464)\n",
    "    Carlos Andres Paez Rojas   (201924257)\n",
    "\n",
    "En este cuaderno vamos a estudiar los sistemas de recomendación de filtrado colaborativo con preferencias implícitas. Vamos a centrarnos en un método incluido en la biblioteca de Spark, conocido como *Mínimos Cuadrados Alternantes* (ALS). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Los sistemas de recomendación se han convertido en parte importante de la industria, potenciando el volumen de ventas a partir de recomendaciones personalizadas. Estos sistemas tienen la prioridad de facilitar la toma de decisiones de los usuarios.  Por ejemplo,  si se tienen muchas opciones de donde elegir, se puede esperar que la elección de un solo producto sea más compleja que si se tienen unas pocas opciones. De esta manera, si se ofrecen los productos adecuados, las ventas pueden incrementar de manera significativa.Bien implementados, los sistemas de recomendación pueden brindar ventajas competitivas importantes para las compañías.\n",
    "\n",
    "\n",
    "Los sistemas de recomendación los podemos ver como motores diseñados para ayudar a los usuarios a encontrar los artículos que les gustan, pero también los podemos pensar como sistemas de información inteligentes que tienen como objetivo ayudar a los usuarios a manejar el problema de la sobrecarga de información. En este sentido, lo que distingue a los sistemas de recomendación de los motores de búsqueda es que aplican el aprendizaje automático de una manera personalizada. Por lo tanto, los sistemas de recomendación permiten construir modelos para satisfacer las preferencias de los usuarios, y encontrar los artículos o servicios necesarios para obtener un mejor sustento y bienestar individual y social.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos algunos ejemplos de sistemas de recomendación en la industria:\n",
    "\n",
    "- Métodos basados en contenido: el punto más importante para este tipo de sistemas es la extracción de patrones. Por ejemplo, la compañía Pandora, que ofrece musica online por *streaming*, extrajo patrones (*features*) de un conjunto de canciones como parte de Proyecto del Genoma Musical. De esta forma, las canciones se respresentaron por un vector de aproximadamente 450 atributos. Una vez se cuenta con este conjunto de patrones, el problema de recomendación se puede estudiar como uno de clasificación binaria. Entonces se construyen modelos que estimen la probabilidad de que a un usuario le guste una canción específica basado en el conjunto de entrenamiento de su historial de canciones, y se recominedan las K canciones que obtengan una mayor probabilidad. Bajo esta aproximación a los sistemas de recomendación por contenido, es crucial la construcción de un buen conjunto de patrones para su aplicación adecuada y exitosa.\n",
    "\n",
    "\n",
    "- Filtrado colaborativo: Bajo la perspectiva del filtrado colaborativo, se busca caracterizar la relación entre usuarios e items sin requerir información específica de los usuarios e items, sino solamente utilizando un valor de preferencia *explícito* o *implícito*, expresando la interacción entre usuario e items. \n",
    "\n",
    "Un **rating explícito** consiste en un valor numérico, categórico o un *like*, mientras que un **rating implícito** consiste en un *índice* de preferencia, como un *click*, una vista o una compra. Un ejemplo bastante conocido es el de la recomendación de películas como en Netflix. Es común contar con ratings valorados en una escala numérica, donde es fácil ver si el usuario a disfrutado o no de la película. Sin embargo, muchas veces los usuarios no proveen ratings para todas las películas, reduciendo la cantidad de datos disponibles para construir las recomendaciones. Netflix al menos puede identificar si un usuario vió una película, sin saber si le gustó o no, simplemente que la vió. Este último es un rating implícito, y suele ser más común que un rating explícito. De esta manera, es factible que al centrarse en ratings implícitos, la información disponible sea mayor (aunque menos expresiva). \n",
    "\n",
    "- Métodos híbridos de filtrado colaborativo e información demográfica: Una red social como Facebook o Linkedin cuenta con bastante información demográfica de los usuarios. Con base en estos datos se pueden identificar usuarios similares a partir de sus características en común. De manera similar al método basado en contenido, se puede construir un vector de patrones para cada usuario y se generan los modelos para predecir la probabilidad de preferir ciertos items.\n",
    "\n",
    "\n",
    "Para una introducción más amplia a los sistemas de recomendación, pueden estudiar estos videos online: \n",
    "1. https://www.youtube.com/watch?v=bLhq63ygoU8&feature=emb_logo\n",
    "\n",
    "2. https://www.youtube.com/watch?v=mRToFXlNBpQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtrado colaborativo y preferencias implíctas\n",
    "\n",
    "Para esta actividad vamos a utilizar el método de mínimos cuadrados alternantes (ALS). Esta técnica busca descomponer una matriz de preferencias $R_{m\\times n}$, con $m$ usuarios y $n$ items, en dos matrices más pequeñas: la matriz de usuarios con sus vectores de patrones latentes $U_{m\\times k}$ y la respectiva matriz de items $V_{k\\times n}$. Se debe tener en cuenta que la matriz $R_{m\\times n}$ tiene muchos datos faltantes (una matriz *sparse*), pues muchos usuarios interactuan con unos pocos items.\n",
    "\n",
    "Entonces, la multiplicación de las matrices $U$ y $V$ permite aproximar la matriz original, y de manera sencilla (pues contaríamos con dos matrices *densas* que incluyen $k$ factores/patrones latentes) podemos construir e interpretar las preferencias estimadas de cada usuario por cada item.\n",
    "\n",
    "Para estimar $U$ y $V$, resulta conveniente utilizar el método de los ALS. De este modo, se resuelve un vector de patrones a la vez, alternando primero para la matriz de usuarios y luego para la matriz de items, y se puede ejecutar de manera paralela (siguiendo la filosofía de Spark). Por ejemplo, inicializando aleatoriamente $U$, fijándola, y resolviendo para $V$, y luego volver y resolver para $U$ utilizando la solución previa para $V$, y repetir hasta converger. \n",
    "\n",
    "Como resultado, el producto punto entre $U$ y $V$ permite estimar $\\hat R$, para todos los pares usuario-item, así no haya habido interacción previa entre los pares. Esta metdología fue presentada en el paper: \n",
    "\n",
    "*Hu, Y., Koren, Y., Volinsky, Ch. (2008) Collaborative filtering for implicit feedback datasets. Proceedings 2008 Eighth IEEE International Conference on Data Mining, Washington, USA, 3022-3026.*\n",
    "\n",
    "Veamos a continuación la implementación del método con un conjunto de datos con preferencias implícitas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Procesamiento de datos\n",
    "\n",
    "Vamos a utilizar el archivo de datos *Online Retail* (del repositorio de Machine Learning UCI), el cual contiene todas las compras para una compañía de venta al por menor en el Reino Unido durante ocho meses.\n",
    "\n",
    "Primero carguemos algunas bibliotecas que van a ser útiles para el pre-procesamiento de los datos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "import random\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos los datos del archivo .xls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "website_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx'\n",
    "\n",
    "try:\n",
    "    retail_data = pd.read_excel(website_url) # No debería tardar mucho\n",
    "except (http.client.IncompleteRead) as e:\n",
    "    retail_data = e.partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos tomar todas las transacciones para cada usuario y preparar los datos para la implementación del ALS. Para ello necesitamos un ID unico por usuario/fila, y un ID unico por item/columna. Los valores de la matriz deben consistir en el número de compras de cada usuario por cada item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos incluye un numero identificativo para cada compra, junto con el codigo de stock *StockCode* que nos sirve como ID del tiem. Además contamos con su descripción, el número de ventas, la fecha de la venta, el precio, el ID del usuario, y el pais de origen del usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  int64         \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  float64       \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "retail_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el resumen de los datos se puede ver que la mayoría de columnas cuentan con información, pero el ID del usuario falta en bastantes filas. Estas observaciones faltantes hacen inservibles las observaciones para nuestros porpósitos (necesitamos el ID del usuario). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = retail_data.loc[pd.isnull(retail_data.CustomerID) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 406829 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    406829 non-null  object        \n",
      " 1   StockCode    406829 non-null  object        \n",
      " 2   Description  406829 non-null  object        \n",
      " 3   Quantity     406829 non-null  int64         \n",
      " 4   InvoiceDate  406829 non-null  datetime64[ns]\n",
      " 5   UnitPrice    406829 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  float64       \n",
      " 7   Country      406829 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 27.9+ MB\n"
     ]
    }
   ],
   "source": [
    "retail.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez limpiamos la base de datos de observaciones faltantes, podemos relacionar todas las compras con su cliente/usuario. \n",
    "\n",
    "Antes de proceder con la matriz de ratings, construyamos una tabla donde podamos encontrar cada ID de item junto con su descripción. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_T = retail[['StockCode', 'Description']].drop_duplicates() # pares item/descripcion\n",
    "items_T['StockCode'] = items_T.StockCode.astype(str) # caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StockCode                          Description\n",
       "0    85123A   WHITE HANGING HEART T-LIGHT HOLDER\n",
       "1     71053                  WHITE METAL LANTERN\n",
       "2    84406B       CREAM CUPID HEARTS COAT HANGER\n",
       "3    84029G  KNITTED UNION FLAG HOT WATER BOTTLE\n",
       "4    84029E       RED WOOLLY HOTTIE WHITE HEART."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procesar la base de datos para:\n",
    "\n",
    "- Agrupar las ventas por codigo de stock e ID del item\n",
    "- Incluir clientes con un total de compras no negativo, y cambiar las sumas que den cero por uno, lo cual puede suceder si un producto es devuelto. Esto lo hacemos para incluir información sobre cualquier tipo de interacción usuario-item. \n",
    "- Construir nuestra matriz de datos tipo *sparse*, que haga uso óptimo de memoria (guarda solamente la ubicación y los valores de los items cuando hay interacción)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerson.guerrero/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/gerson.guerrero/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Toma el ID de usuario como Entero y selecciona variables relevantes\n",
    "retail['CustomerID'] = retail.CustomerID.astype(int) \n",
    "retail = retail[['StockCode', 'Quantity', 'CustomerID']] \n",
    "\n",
    "# Agrupamos e indicamos si hubo interacción\n",
    "g_retail = retail.groupby(['CustomerID', 'StockCode']).sum().reset_index() \n",
    "g_retail.Quantity.loc[g_retail.Quantity == 0] = 1 \n",
    "\n",
    "# Nos quedamos con usuarios con compras positivas\n",
    "g_ventas = g_retail.query('Quantity > 0') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las ventas agrupadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>23166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>16008</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12347</td>\n",
       "      <td>17021</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12347</td>\n",
       "      <td>20665</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12347</td>\n",
       "      <td>20719</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID StockCode  Quantity\n",
       "0       12346     23166         1\n",
       "1       12347     16008        24\n",
       "2       12347     17021        36\n",
       "3       12347     20665         6\n",
       "4       12347     20719        40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_ventas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, en lugar de representar un rating explícito, podemos tomar el número de items adquiridos como una *proxy* de la **confianza** sobre la intensidad de la interacción usuario-item. Es decir, entre más unidades del item se adquieren por parte de un usuario, mayor será el peso para el rating en nuestra matriz de preferencias. \n",
    "\n",
    "A continuación creamos la matriz de tipo *sparse*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios = list(np.sort(g_ventas.CustomerID.unique())) \n",
    "items = list(g_ventas.StockCode.unique()) \n",
    "confianza = list(g_ventas.Quantity) \n",
    "\n",
    "# Construimos la matriz\n",
    "filas = g_ventas.CustomerID.astype('category').cat.codes \n",
    "cols = g_ventas.StockCode.astype('category').cat.codes \n",
    "prefs_sparse = sparse.csr_matrix((confianza, (filas, cols)), shape=(len(usuarios), len(items)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos la matriz que hemos declarado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4338x3664 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 266723 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefs_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz tiene 4338 usuarios y 3664 items. De todas las posibles interacciones, se tienen 266723 con alguna compra. \n",
    "\n",
    "Esto es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.32190920694744"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interacciones posibles\n",
    "mat_dim = prefs_sparse.shape[0]*prefs_sparse.shape[1] \n",
    "\n",
    "# Numero de interacciones\n",
    "num_ventas = len(prefs_sparse.nonzero()[0]) \n",
    "sparsity = 100*(1 - (num_ventas/mat_dim))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 98.3% de la matriz de interacciones es nula o *sparse*. \n",
    "\n",
    "Con el fin de aplicar los algoritmos de filtrado colaborativo, el porcentaje no debería superar un 99.5% aprox. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Experimentos de aprendizaje \n",
    "### Entrenamiento/Prueba vs. Validacion cruzada\n",
    "\n",
    "Normalmente para problemas de aprendizaje computacional supervisado, debemos probar si el modelo que entrenamos generaliza de buena manera la muestra de datos utilizada, esto es, si predice de buena manera observaciones nuevas que no pertenecen a la muestra inicial. Esto se suele hacer creando un conjunto de prueba completamente distinto al conjunto de entrenamiento, tomando una muestra aleatoria del conjunto total de observaciones (en nuestro caso una muestra aleatoria de usuarios) y separandola del conjunto de entrenamiento. \n",
    "\n",
    "Ahora, bajo el método de filtrado colaborativo esto no funciona del todo porque necesitamos de todas las interacciones usuario-item para encontrar una factorización apropiada de la  matriz de preferencias. Una mejor alternativa consiste en *esconder* aleatoriamente cierta proporción de interacciones del modelo durante la fase de entrenamiento. Luego, se revisa en la fase de validación cuántos items de los que fueron recomendados en verdad terminaron siendo comprados por los usuarios. El desempeño del modelo se puede evaluar a partir de la tasa de aciertos del modelo en validación. De todos modos, también podríamos tomar un punto del tiempo para separar el entrenamiento de la predicción y evaluar el error en predicción. \n",
    "\n",
    "En este caso, tenemos un periodo de tiempo corto y es poco probable que los productos que se hayan adquirido una vez vuelvan a ser aduqiridos en tan poco tiempo. Entonces, el conjunto de entrenamiento va a consistir en los datos originales pero omitiendo un porcentaje aleatorio de interacciones, *enmascaradas* como cero. De esta manera se asume para cada iteracción que esos items enmasacardos no han sido adquiridos por el usuario, y probamos si el algoritmo le recomendaría esos productos. En consecuencia, si se puede observar que los usuarios terminaron comprando esos productos recomendados, se puede concluir que el sistema hace bien su trabajo.\n",
    "\n",
    "También podemos verificar que nuestro sistema mejore una recomendación basada en la popularidad media, como un modelo de referencia (*Baseline*).\n",
    "\n",
    "\n",
    "A continuación ejecutamos nuestro propio codigo para el ALS. Primero escribimos una función para enmascarar los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrena(ratings, pct_val = 0.2):\n",
    "    '''\n",
    "    Input: Matriz de ratings\n",
    "    Output: matriz de entrenamiento CE y de validacion CV, y user_inds\n",
    "    \n",
    "    Esta función toma la matriz orginal y enmascara un porcentaje de ratings pata la validacion\n",
    "    El conjunto de validacion (CV) va a tener todos los ratings originales, mientras que el de entrenamiento (CE)\n",
    "    reemplaza el porcentaje señalado con ceros\n",
    "    \n",
    "    pct_val: porcentaje de iteraciones a enmascarar\n",
    "    user_inds: lista de usuarios aleatoriamente elegidos y enmascarados en CE.\n",
    "    '''\n",
    "    \n",
    "    random.seed(0) # Semilla aeatoria\n",
    "    \n",
    "    CV = ratings.copy() \n",
    "    CV[CV != 0] = 1 # CV como una matriz binaria\n",
    "    \n",
    "    CE = ratings.copy() \n",
    "    non0_inds = CE.nonzero() # Indices donde hay interaccion\n",
    "    non0_pares = list(zip(non0_inds[0], non0_inds[1])) # lista de indices usuario-item con interaccion\n",
    "    \n",
    "    num_muestra = int(np.ceil(pct_val*len(non0_pares))) \n",
    "    muestra = random.sample(non0_pares, num_muestra) # sub-muestreo sin reemplazo\n",
    "    \n",
    "    user_inds = [index[0] for index in muestra] # indices de usuario\n",
    "    item_inds = [index[1] for index in muestra] # inidices de items\n",
    "    \n",
    "    CE[user_inds, item_inds] = 0 # Asigna 0 sobre las observaciones elegidas\n",
    "    CE.eliminate_zeros() # Elimina los ceros en el arreglo sparce\n",
    "    return CE, CV, list(set(user_inds)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la funcion anterior tenemos nuestro conjunto de entrenamiento, un conjunto de validacion  binario (compra/no compra) y una lista de los usuarios dejados por fuera del entrenamiento para validacion. Entonces, si enmascaramos el 20% de los usuarios, evaluaremos el desempeño del modelo sobre estos usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE, CV, users_V = entrena(prefs_sparse, pct_val = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Método de Mínimos Cuadrados Alternantes (ALS)\n",
    "Ahora podemos implementar el ALS sobre nuestros ratings implícitos (siguiendo el paper de  Hu et al. 2008).\n",
    "\n",
    "En primera instancia, debemos transformar la matriz de preferencias en una matriz de confianza:\n",
    "\n",
    "$$\n",
    "C_{ui}=1+\\alpha r_{ui}\n",
    "$$\n",
    "\n",
    "donde $C_{ui}$ representa la confianza del usuario $u$ sobre el item $i$ y $\\alpha$ representa un factor de incremento lineal con respecto al rating del usuario.\n",
    "\n",
    "\n",
    "Enfocándonos en el modelo de factores ($f$) latentes, le asignamos a cada usuario un vector $x_u \\in \\mathbb{R}^f$ y a cada item un vector $y_i\\in \\mathbb{R}^f$, donde la prediccion corresponde con el producto interno $$ \\hat p_{ui} = x^T_u y_i. $$\n",
    "Recordemos que esta predicción es binaria.\n",
    "\n",
    "En este caso vamos a incorporar el parámetro de confianza sobre la minimización de la función obejtivo:\n",
    "$$\n",
    "\\min_{x,y} \\sum_{u,i} c_{ui}(p_{ui} - x^T_u y_i)^2 + \\lambda\\bigl( \\sum_u ||x_u||^2 + \\sum_i ||y_i ||^2 \\bigr) \\tag{1}\n",
    "$$\n",
    "\n",
    "La clave para resolver este problema mediante ALS consiste en que al fijar los factores de usuario o los de item, la función de coste se vuelve cuadrática. Al diferenciar $(1)$ podemos minimizar la función para los usuarios:\n",
    "$$\n",
    "x_u=(Y^TC_uY+\\lambda I)^{−1}Y^TC_up(u)\n",
    "$$\n",
    "y de manera similar para los items,\n",
    "$$\n",
    "y_i=(X^TC_iX+\\lambda I)^{−1}X^TC_yp(i)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_con_ALS(CE, lambda_val = 0.1, alpha = 40, itera = 10, factores = 20, semilla = 0):\n",
    "    '''\n",
    "    Input:\n",
    "    CE: conjunto de entrenamiento con m usuarios y n items. Matriz sparse csr\n",
    "    lambda_val: parametro de regularizacion ALS. \n",
    "    alpha: Parametro de confianza para el rating implicito \n",
    "    itera: numero de iteraciones para el ALS. Un  mayor numero permite una mejor convergencia\n",
    "    factores: el numero de factores latentes. Incrementar su numero aumenta el riesgo de sobre-ajuste \n",
    "    semilla: semilla aleatoria para reproducibilidad\n",
    "    Output:\n",
    "    El vector de factores o patrones para usuarios y para items.\n",
    "    '''\n",
    "    \n",
    "    # declaramos la matriz de confianza\n",
    "    \n",
    "    conf = (alpha*CE) \n",
    "    \n",
    "    num_user = conf.shape[0]\n",
    "    num_item = conf.shape[1] \n",
    "    \n",
    "    # Incializacion aleatoria de los vectores de usuario e item\n",
    "    random = np.random.RandomState(semilla)\n",
    "    X = sparse.csr_matrix(random.normal(size = (num_user, factores))) \n",
    "    Y = sparse.csr_matrix(random.normal(size = (num_item, factores))) \n",
    "    \n",
    "    X_eye = sparse.eye(num_user)\n",
    "    Y_eye = sparse.eye(num_item)\n",
    "    lambda_eye = lambda_val * sparse.eye(factores) # termino de regularizacion lambda*I. \n",
    "    \n",
    "    # Bucle ALS\n",
    "   \n",
    "    for iter_step in range(itera): # Itera alternando entre X e Y\n",
    "        # Calculamos yTy, xTx al principio de cada iteracion para optimizar el coste computacional\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "        # Fijamos Y\n",
    "        for u in range(num_user):\n",
    "            conf_samp = conf[u,:].toarray() # convierte a un vector denso la fila del usuario (de la matriz de confianza)\n",
    "            pref = conf_samp.copy() \n",
    "            pref[pref != 0] = 1 # Vector de preferencia binario\n",
    "            CuI = sparse.diags(conf_samp, [0]) # Término Cu-I \n",
    "            yTCuIY = Y.T.dot(CuI).dot(Y) # Termino yT(Cu-I)Y  \n",
    "            yTCupu = Y.T.dot(CuI + Y_eye).dot(pref.T) # Término yTCuPu\n",
    "            X[u] = spsolve(yTy + yTCuIY + lambda_eye, yTCupu) \n",
    "            # Resuelve para Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu, Ecuacion 4 del paper \n",
    "        \n",
    "        # Fijamos X\n",
    "        for i in range(num_item):\n",
    "            conf_samp = conf[:,i].T.toarray() # Se transpone y se convierte a matriz densa\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1 # Crea la matriz binaria\n",
    "            CiI = sparse.diags(conf_samp, [0]) # Calcula el termino Cu-I \n",
    "            xTCiIX = X.T.dot(CiI).dot(X) # Se calcula el termino xT(Cu-I)X \n",
    "            xTCiPi = X.T.dot(CiI + X_eye).dot(pref.T) # Se calcula el temrino xTCiPi \n",
    "            Y[i] = spsolve(xTx + xTCiIX + lambda_eye, xTCiPi) \n",
    "            # Resuelve para Yi = ((xTx + xT(Cu-I)X) + lambda*I)^-1)xTCiPi\n",
    "    \n",
    "    return X, Y.T \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentemos diez iteraciones para verificar que el codigo funciona, tomando 20 factores latentes junto con un coefiencte de confianza de 15 y una regularización de 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inicia nuestro ALS:  2020-11-15 23:00:23.369335\n",
      "Tiempo en completarse las 10 iteraciones:  0:03:38.789891\n"
     ]
    }
   ],
   "source": [
    "tiempo0 = datetime.datetime.now()\n",
    "print('\\nInicia nuestro ALS: ', tiempo0)\n",
    "\n",
    "user_vecs, item_vecs = implicit_con_ALS(CE, lambda_val = 0.1, alpha = 15, itera = 10, factores = 20)\n",
    "\n",
    "print('Tiempo en completarse las 10 iteraciones: ', datetime.datetime.now()-tiempo0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los ratings para un usuario dado tomando el producto punto entre los vectores de usuario e item (U y V):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01415129,  0.00488818, -0.01436672, -0.0570171 , -0.03146238])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs[0,:].dot(item_vecs).toarray()[0,:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los valores de preferencia estimados para el primer usuario sobre los primeros 5 items, de un total de 3664 en stock. \n",
    "\n",
    "### Pregunta\n",
    "Cuál es el item con una mayor preferencia sobre todo el stock de productos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3348    0.646422\n",
       "2602    0.644717\n",
       "1740    0.636651\n",
       "2406    0.608103\n",
       "2046    0.607248\n",
       "966     0.603986\n",
       "906     0.600370\n",
       "353     0.592518\n",
       "1251    0.591447\n",
       "1538    0.590564\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(user_vecs.dot(item_vecs).toarray()).mean(axis=0).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El producto 3348 el que mayor preferencia promedio presenta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implicit: Implementacion óptima del ALS\n",
    "\n",
    "Hasta ahora no hemos indagando en la convergencia del modelo, lo cual puede tomar más tiempo, y por eso mismo, es recomendable hacer uso de un código optimizado. \n",
    "\n",
    "Hasta el momento hacemos uso de bastantes bucles y no tomamos ventaja del hecho de que el algoritmo es paralelizable, pues cada iteración se puede realizar sobre los vectores de item o de usuario de manera independiente. Para ello podemos hacer uso de la versión de ALS para Python (utilizando Cython) que paraleliza el codigo entre distintos procesadores. Antes tenemos que instalar la bilbioteca `implicit`. \n",
    "\n",
    "Para mayores detalles, puede investigar: https://pypi.org/project/implicit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalarlo desde el prompt de Anaconda (https://anaconda.org/conda-forge/implicit):\n",
    "\n",
    "`conda install -c conda-forge implicit` \n",
    "\n",
    "También debemos chequear que la version de `scipy` sea 0.16 o posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::anaconda==2020.02=py37_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: done\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/gerson.guerrero/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - implicit\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.9.2                |   py37hf985489_0         3.0 MB  conda-forge\n",
      "    implicit-0.4.0             |   py37h86efe34_0         571 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  implicit           conda-forge/osx-64::implicit-0.4.0-py37h86efe34_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                4.8.4-py37hc8dfbb8_2 --> 4.9.2-py37hf985489_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.9.2          | 3.0 MB    | ##################################### | 100% \n",
      "implicit-0.4.0       | 571 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge implicit -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta versión no se hace uso explícito del parametro $\\alpha$ que utilizamos para ponderar la confianza de los ratings. Este paso lo debemos hacer nosotros antes de introudcir el input. También necesitamos declarar el tipo de la matriz como *double* para ejecutar la función de ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n",
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391a14a0462d47d0898bbec19c9e411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 15\n",
    "user_vecs, item_vecs = implicit.alternating_least_squares((CE*alpha).astype('double'), \n",
    "                                                          factors=20, \n",
    "                                                          regularization = 0.1, \n",
    "                                                          iterations = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta implementación de `implicit` conseguimos unas mejores predicciones tras utilizar un mayor número de iteraciones y conseguir una mejor convergencia del modelo. Pero ahora vemos cómo medimos el desempeño del modelo.\n",
    "\n",
    "\n",
    "## 4. Evaluación del sistema de recomendación\n",
    "\n",
    "Recordemos que nuestro conjunto de entrenamiento había dejado por fuera el 20% de las observaciones con ventas. Ahora vamos a evaluar el desempeño del modelo sobre este 20%. Específicamente debemos contrastar si las recomendaciones obtenidas por nuestro sistema cazan con los items que los usuarios temrinaron comprando. \n",
    "\n",
    "Una métrica muy usual es el Area bajo la Curva ROC (Receiver Operating Characteristic), o AUC. Una mayor area significa que los items recomendados en las posiciones altas de la lista de recomendación terminan siendo comprados por los usuarios. En esta parte implementaremos el AUC para evaluar la calidad del ranking de nuestras recomendaciones.\n",
    "\n",
    "El AUC se consigue al graficar la tasa de verdaderos positivos (TPR) contra la tasa de falsos positivos (FPR) para todos los umbrales de decisión, dadas por:\n",
    "\\begin{equation}\n",
    "\\label{tpr}\n",
    "TPR=\\frac{TP}{TP+FN}  \n",
    "\\end{equation}\t  \n",
    "\\begin{equation}\n",
    "\\label{fpr}\n",
    "FPR=\\frac{FP}{FP+TN}  \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Para ello implementamos una función que calcule el AUC para cualquier usuario que tenga al menos un item en el conjunto de validación. Como benchmark de comparación tomamos el AUC que se hubiera obtenido si se recomendaran los items más populares. Con este fin, utilizamos la biblioteca Scikit-learn para calcular las tasas TPR y FPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(preds, prueba):\n",
    "    '''\n",
    "    Esta funcion obtiene el AUC. \n",
    "    Input:\n",
    "    parameters:\n",
    "    preds: las predicciones del sistema\n",
    "    prueba: las ventas verdaderas\n",
    "    Output:\n",
    "    AUC\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, umbrales = metrics.roc_curve(prueba, preds)\n",
    "    return metrics.auc(fpr, tpr)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.zeros(67),np.ones(12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba=np.concatenate((np.zeros(54),np.ones(25)))\n",
    "preds=np.concatenate((np.zeros(67),np.ones(12)))\n",
    "fpr, tpr, umbrales = metrics.roc_curve(prueba, preds)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora utilizamos esta función para calcular el AUC para cada usuario e el conjunto de validación (que coinciden con las observaciones enmascaradas del conjunto de entrenamiento). También calculamos el AUC para los items más populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC_val(CE, users_V, preds, CV):\n",
    "    '''\n",
    "    Esta funcion calcula el AUC medio por usuario para todo usuario en el conjunto de validacion\n",
    "    Input:\n",
    "    CE: Conjunto de entrnamiento con un porcentaje de las interacciones originales enamscaradas\n",
    "    preds: la matriz con las predicciones de los ratings para cada par usuario-item (lista\n",
    "    con vectores de usuario y vectores de items)\n",
    "    users_V: indices de los usuarios de validacion\n",
    "    CV: conjunto de validacion \n",
    "    Output:\n",
    "    AUC medio del CV para las interacciones usuario-item y para los items más populares\n",
    "    '''\n",
    "    \n",
    "    # Inicializamos la lista para guardar el AUC de validacion \n",
    "    rec_auc = [] \n",
    "    # y el AUC para la recomendación por popularidad\n",
    "    pop_auc = [] \n",
    "    \n",
    "    # Tomamos la suma de interacciones por item para encontrar lo más popular\n",
    "    pop_items = np.array(CV.sum(axis = 0)).reshape(-1) \n",
    "    item_vecs = preds[1]\n",
    "    \n",
    "    for user in users_V: \n",
    "        user_i = CE[user,:].toarray().reshape(-1) # usuario de validacion\n",
    "        user_val = np.where(user_i == 0) # \n",
    "        \n",
    "        # Toma la prediccion para el usuario-item\n",
    "        user_vec = preds[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,user_val].reshape(-1)\n",
    "        \n",
    "        # Selecciona los ratings estimados para el usuario \n",
    "        actual = CV[user,:].toarray()[0,user_val].reshape(-1) \n",
    "        \n",
    "        # Toma los pares con interacciones binarias de los datos originales\n",
    "        pop = pop_items[user_val] # Popularidad del item\n",
    "        rec_auc.append(auc_score(pred, actual)) # Calcula y guarda el AUC para el ususario\n",
    "        pop_auc.append(auc_score(pop, actual)) # Calcula el AUC por popularidad\n",
    "\n",
    "    \n",
    "    return float('%.3f'%np.mean(rec_auc)), float('%.3f'%np.mean(pop_auc))  \n",
    "   # Devuelve el AUC medio para validacion y por popularidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar la funcion para evaluar el desempeño de nuestro sistema. Para ello, debemos tomar la salida de nuestra funcion ALS y pasarla a formato de csr_matrix, y trasponer los vectores de items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.872, 0.815)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_val(CE, users_V, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], CV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que nuestro sistema de recomendación es al menos mejor que la recomendación basada en popularidad, con un AUC de 0.87 frente a uno de 0.814. \n",
    "\n",
    "### Ejercicio práctico\n",
    "Revise su algoritmo e intente optimizar los hiper-parámetros para mejorar el valor del AUC. Puede intentar himplementar validación cruzada además de la prueba para controlar el riesgo de sobre-ajuste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable([\"alpha\", \"regu\", \"fact\", \"AUC validation\", \"AUC popularity\"])\n",
    "a = {0:10,1:15, 2:20}\n",
    "f = {0:15, 1:20, 2:25}\n",
    "r = {0:0.005, 1:0.01, 2:0.02}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            user_vecs, item_vecs = implicit.alternating_least_squares((CE*a[i]).astype('double'), \n",
    "                                                                      factors=f[j], \n",
    "                                                                      regularization = r[k], \n",
    "                                                                      iterations = 50)            \n",
    "            AUC_VAL, AUC_POP = AUC_val(CE, users_V, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], CV)\n",
    "            \n",
    "            x.add_row([a[i],r[k],f[j],AUC_VAL,AUC_POP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------------+----------------+\n",
      "| alpha |  regu | fact | AUC validation | AUC popularity |\n",
      "+-------+-------+------+----------------+----------------+\n",
      "|   10  | 0.005 |  15  |     0.869      |     0.815      |\n",
      "|   10  |  0.01 |  15  |     0.869      |     0.815      |\n",
      "|   10  |  0.02 |  15  |      0.87      |     0.815      |\n",
      "|   10  | 0.005 |  20  |     0.871      |     0.815      |\n",
      "|   10  |  0.01 |  20  |     0.872      |     0.815      |\n",
      "|   10  |  0.02 |  20  |     0.871      |     0.815      |\n",
      "|   10  | 0.005 |  25  |     0.871      |     0.815      |\n",
      "|   10  |  0.01 |  25  |     0.871      |     0.815      |\n",
      "|   10  |  0.02 |  25  |     0.871      |     0.815      |\n",
      "|   15  | 0.005 |  15  |      0.87      |     0.815      |\n",
      "|   15  |  0.01 |  15  |     0.869      |     0.815      |\n",
      "|   15  |  0.02 |  15  |      0.87      |     0.815      |\n",
      "|   15  | 0.005 |  20  |     0.873      |     0.815      |\n",
      "|   15  |  0.01 |  20  |     0.871      |     0.815      |\n",
      "|   15  |  0.02 |  20  |     0.872      |     0.815      |\n",
      "|   15  | 0.005 |  25  |     0.872      |     0.815      |\n",
      "|   15  |  0.01 |  25  |     0.872      |     0.815      |\n",
      "|   15  |  0.02 |  25  |     0.871      |     0.815      |\n",
      "|   20  | 0.005 |  15  |      0.87      |     0.815      |\n",
      "|   20  |  0.01 |  15  |     0.869      |     0.815      |\n",
      "|   20  |  0.02 |  15  |     0.869      |     0.815      |\n",
      "|   20  | 0.005 |  20  |     0.871      |     0.815      |\n",
      "|   20  |  0.01 |  20  |     0.871      |     0.815      |\n",
      "|   20  |  0.02 |  20  |     0.872      |     0.815      |\n",
      "|   20  | 0.005 |  25  |     0.873      |     0.815      |\n",
      "|   20  |  0.01 |  25  |      0.87      |     0.815      |\n",
      "|   20  |  0.02 |  25  |     0.871      |     0.815      |\n",
      "+-------+-------+------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final observamos que con los hiperparámetros. alfa=20, factores=20, y regularización=0.005 tenemos un AUC de 0.873 en la base de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios finales\n",
    "\n",
    "Hemos visto cómo diseñar y evaluar un sistema de recomendación con ratings implícitos. En implementaciones de la vida real, si el tamaño de la matriz de ratings es muy grande, puede ser más práctica su implementación en Spark:\n",
    "https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html\n",
    "\n",
    "También se pueden seguir explorando los sistemas de recomendación híbridos, incorporando información propia de los usuarios e items además de su comportamiento de compras. La librería de Python `LightFM` de Maciej Kula permite implementar distintos algoritmos con preferencias implícitas y explícitas:\n",
    "https://making.lyst.com/lightfm/docs/home.html\n",
    "\n",
    "\n",
    "\n",
    "Para los sistemas de recomendación con ratings explícitos podemos usar `SurPRISE`, que estudiaremos las próximas sesiones, o también pueden explorar este blog:\n",
    "\n",
    "*Explicit Matrix Factorization: ALS, SGD, and All That Jazz*, por Ethan Rosenthal\n",
    "    https://www.ethanrosenthal.com/2016/01/09/explicit-matrix-factorization-sgd-als/\n",
    "\n",
    "\n",
    "Finalmente, si buscan datos para la implementación de sistemas de recomendación, pueden explorar el siguiente link: https://gist.github.com/entaroadun/1653794\n",
    "\n",
    "\n",
    "### Reflexion final\n",
    "\n",
    "Pensemos que si bien el sistema no recomienda items que ya han sido comprados, sí puede estar recomendando otra vez el mismo tipo de productos. Por ejemplo, si un usuario compra una lavadora, ¿tiene sentido recomendarle otra lavadora?\n",
    "\n",
    "Hay ciertos productos que se compran solo una vez, y requieren más bien de otros productos complementarios que combinen bien con su uso.\n",
    "\n",
    "Piense en una estrategia para desarrollar un sistema de recomendación que no recomiende siempre productos sustitutos o muy similares entre sí, es decir, productos que cumplan exactamente las mismas funciones que lo que ya han sido adquiridos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

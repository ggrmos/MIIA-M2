{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h1> <img src=\"https://serea2017.uniandes.edu.co/images/Logo.png\" height=\"120\" width=\"400\" align=\"Center\" /><br>\n",
    " \n",
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    " \n",
    "\n",
    "\n",
    " # Introducción al aprendizaje computacional\n",
    " \n",
    "## Actividad 1 -- 19 Agosto 2020\n",
    " \n",
    "\n",
    "\n",
    " ### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    " \n",
    "\n",
    "\n",
    "                          Nombres                  Usuario            Código\n",
    "\n",
    "            - Camilo Andrés Angarita Ortiz        ca.angarita967  201111642      \n",
    "\n",
    "            - Javier Alfonso Lesmes Patiño        ja.lesmes21     200820243\n",
    "\n",
    "            - Gerson Arturo Guerrero              ga.guerrero     201823464 \n",
    "\n",
    "            - Elquin Huertas Ramírez               e.huertas      201920061\n",
    " \n",
    "En esta actividad vamos a estudiar una primera aproximación a los modelos de aprendizaje computacional, utilizando como base un problema de clasifiación y el modelo de clasificación logístico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aprendizaje computacional\n",
    "\n",
    "El aprendizaje computacional o **Machine Learning** (ML), utiliza algoritmos con parámetros libres que se puedan ajustar de manera automática, con el objetivo de mejorar el desempeño de los modelos a partir de la información disponible.\n",
    "\n",
    "El aprendizaje computacional se circunscribe en el campo de la Inteligencia Computacional, o lo que se conoce como Inteligencia Artificial, mediante la búsqueda de patrones a partir de los *Datos*. Entonces, los algoritmos desarrollados dentro del Machine Learning (ML a partir de ahora) se pueden entender como los bloques fundacionales que permiten aprender computacionalmente a partir de los datos. De esta manera, generalizando los datos en lugar de solo almacenarlos y devolver busquedas específicas, como en los sistemas relacionales de bases de datos.\n",
    "\n",
    "\n",
    "### Tipos de aprendizaje\n",
    "\n",
    "Los tipos de problemas sobre los que se trabaja en ML se pueden entender como de tipo **supervisado**, **no supervisado**, y **semi-supervisado**. \n",
    "\n",
    "**Aprendizaje supervisado**\n",
    "\n",
    "El aprendizaje supervisado se refiere a modelos, o conjuntos de algoritmos, que aproximan o estiman una función $f(x)$ que representa la relación entre la variable dependiente $Y$ (etiqueta o valor objetivo) y el conjunto de variables independientes $X$. Por ello a los algoritmos de tipo supervisado se les asocia usualmente con modelos predictivos, donde dado un conjunto de datos $X$, se puede predecir un nuevo valor de la variable dependiente $Y$. \n",
    "\n",
    "De acuerdo con el tipo de valores en $Y$, se pueden definir dos tipos principales de problemas y algoritmos para analizar los datos:\n",
    "\n",
    "- Problemas de clasificación\n",
    "\n",
    "Siempre que la variable $Y$ se refiera a un grupo de categorías (valores sin ningún orden en particular), como por ejemplo bueno/malo, pequeño/grande, la tarea de predecir $Y$ puede ser considerada como un problema de clasificación. En este sentido, las variables de salida se conocen como etiquetas o categorías.\n",
    "\n",
    "- Problemas de regresión\n",
    "\n",
    "Un problema de regresión consiste en estimar y/o predecir una variable dependiente (o valor objetivo) $Y$ con valores continuos. Por ejemplo, predecir el precio de una vivienda, de acciones, alimentos, etc. \n",
    "\n",
    "**Aprendizaje no-supervisado**\n",
    "    \n",
    "El aprendizaje no-supervisado considera problemas donde la variable dependiente $Y$, o las etiquetas para el conjunto de datos, no está disponible. Es decir, cuando $Y$ no está contenida en el conjunto de datos. Entonces, en lugar de estimar o predecir una variable, un algoritmo no-supervisado utiliza técnicas sobre el conjunto de datos de entrada $X$ para detectar patrones, encontrar reglas, o resumir y agrupar los datos. Usualmente, los algoritmos no-supervisados son utilizados para el análisis descriptivo y la modelación, donde se necesita una primera aproximación a los datos, desarrollar una intuición y extraer nuevo conocmiento que es desconocido para el analista y/o experto. \n",
    "\n",
    "En el aprendizaje no-supervisado, se tienen dos tareas principales, la reducción de dimensionalidad y el análisis de clustering.\n",
    "\n",
    "- Reducción de dimensionalidad \n",
    "\n",
    "La reducción de dimensionalidad busca encontrar la estructura subyacente de los datos, reduciendo la cantidad de información disponible en el conjunto de datos $X$. Por ejemlo, es muy conocido el análisis de componentes principales. \n",
    "\n",
    "- Clustering \n",
    "\n",
    "El análisis de clustering consiste en agrupar un conjunto de datos $X$ de manera que cada grupo contenga observaciones más similares entre sí que con las observaciones de otros grupos. Estos grupos son denominados *clusters*. Es una técnica bastante común para la exploración de los datos y su análisis. \n",
    "\n",
    "\n",
    "#### Otros tipos de aprendizaje\n",
    "\n",
    "Más allá de estos dos tipos de aprendizaje presentados anteriormente, existen otros tipos que son bastante útiles dependiendo de la naturaleza del problema. Por ejemplo, el **aprendizaje semi-supervisado** (https://medium.com/inside-machine-learning/placeholder-3557ebb3d470) o el **aprendizaje por refuerzo** (https://medium.com/machine-learning-for-humans/reinforcement-learning-6eacf258b265) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problema de clasificación: riesgo de default\n",
    "\n",
    "### 2.1 Datos\n",
    "\n",
    "Como hemos visto, una tarea muy usual dentro del ML es la de la clasificación. Pero antes, vamos a importar las bibliotecas que vamos a usar en este cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algunos paquetes iniciales que vamos a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"germancredit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "      <th>checkingstatus1</th>\n",
       "      <th>duration</th>\n",
       "      <th>history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>employ</th>\n",
       "      <th>installment</th>\n",
       "      <th>status</th>\n",
       "      <th>...</th>\n",
       "      <th>residence</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>otherplans</th>\n",
       "      <th>housing</th>\n",
       "      <th>cards</th>\n",
       "      <th>job</th>\n",
       "      <th>liable</th>\n",
       "      <th>tele</th>\n",
       "      <th>foreign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Default checkingstatus1  duration history purpose  amount savings employ  \\\n",
       "0        0             A11         6     A34     A43    1169     A65    A75   \n",
       "1        1             A12        48     A32     A43    5951     A61    A73   \n",
       "2        0             A14        12     A34     A46    2096     A61    A74   \n",
       "3        0             A11        42     A32     A42    7882     A61    A74   \n",
       "4        1             A11        24     A33     A40    4870     A61    A73   \n",
       "\n",
       "   installment status  ... residence  property age  otherplans housing cards  \\\n",
       "0            4    A93  ...         4      A121  67        A143    A152     2   \n",
       "1            2    A92  ...         2      A121  22        A143    A152     1   \n",
       "2            2    A93  ...         3      A121  49        A143    A152     1   \n",
       "3            2    A93  ...         4      A122  45        A143    A153     1   \n",
       "4            3    A93  ...         4      A124  53        A143    A153     2   \n",
       "\n",
       "    job liable  tele foreign  \n",
       "0  A173      1  A192    A201  \n",
       "1  A173      1  A191    A201  \n",
       "2  A172      2  A191    A201  \n",
       "3  A173      2  A191    A201  \n",
       "4  A173      2  A191    A201  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Default             int64\n",
       "checkingstatus1    object\n",
       "duration            int64\n",
       "history            object\n",
       "purpose            object\n",
       "amount              int64\n",
       "savings            object\n",
       "employ             object\n",
       "installment         int64\n",
       "status             object\n",
       "others             object\n",
       "residence           int64\n",
       "property           object\n",
       "age                 int64\n",
       "otherplans         object\n",
       "housing            object\n",
       "cards               int64\n",
       "job                object\n",
       "liable              int64\n",
       "tele               object\n",
       "foreign            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    700\n",
       "1    300\n",
       "Name: Default, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Default.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase positiva (default=1) tiene menos casos.  Además, es 5 veces más costoso clasificar a un usuario como bueno (Defualt=0) cuando es malo (Default=1), que clasificarlo como malo cuando es bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A201    963\n",
       "A202     37\n",
       "Name: foreign, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.foreign.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la mayoría de clientes de la base de datos son extranjeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Codificacion de variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Default  duration  amount  installment  residence  age  cards  liable  \\\n",
      "0        0         6    1169            4          4   67      2       1   \n",
      "1        1        48    5951            2          2   22      1       1   \n",
      "2        0        12    2096            2          3   49      1       2   \n",
      "3        0        42    7882            2          4   45      1       2   \n",
      "4        1        24    4870            3          4   53      2       2   \n",
      "\n",
      "   checkingstatus1_A11  checkingstatus1_A12  ...  housing_A152  housing_A153  \\\n",
      "0                    1                    0  ...             1             0   \n",
      "1                    0                    1  ...             1             0   \n",
      "2                    0                    0  ...             1             0   \n",
      "3                    1                    0  ...             0             1   \n",
      "4                    1                    0  ...             0             1   \n",
      "\n",
      "   job_A171  job_A172  job_A173  job_A174  tele_A191  tele_A192  foreign_A201  \\\n",
      "0         0         0         1         0          0          1             1   \n",
      "1         0         0         1         0          1          0             1   \n",
      "2         0         1         0         0          1          0             1   \n",
      "3         0         0         1         0          1          0             1   \n",
      "4         0         0         1         0          1          0             1   \n",
      "\n",
      "   foreign_A202  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "credit_1 = data.copy()\n",
    "credit_1 = pd.get_dummies(credit_1, columns=['checkingstatus1','history','purpose','savings',\n",
    "                                   'employ','status','others','property','otherplans','housing','job','tele', \n",
    "                                   'foreign'], prefix = ['checkingstatus1','history','purpose','savings',\n",
    "                                   'employ','status','others','property','otherplans','housing','job','tele', \n",
    "                                   'foreign'])\n",
    "\n",
    "print(credit_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 61)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = credit_1.iloc[:, 1:62]#[['duration','amount','installment','residence','age','cards','liable']]\n",
    "Y = credit_1.iloc[:, 0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regresión logística\n",
    "\n",
    "Podemos estudiar un problema de clasificación desde una perspectiva probabilística, examinando una situación donde la variable respuesta ($Y_i$) consiste de dos categorías ($\\{0,1\\}$). La *regresión logística* estima la probabilidad de que una observación pertenezca a una de las dos categorías.\n",
    "\n",
    "Entonces se modela la función de probabilidad $p(Y_i=1)$ de tal manera que tome un valor entre 0 y 1. La función de regresión logística consiste en la función *sigmoide* ($\\sigma(\\cdot)$) $$ p(Y_i)=p(Y_i=1)=\\frac{e^{\\beta_0 + \\beta_1X_{1} + ... + \\beta_k X_{k}}}{1+e^{\\beta_0 + \\beta_1X_{1} + ... + \\beta_k X_{k}}}=\\frac{e^{Z_i}}{1+e^{Z_i}}=\\sigma(Z_i)$$\n",
    "donde se tiene que \n",
    "$$log\\frac{p(Y_i)}{1-p(Y_i)}=\\beta_0 + \\beta_1X_{1} + ... + \\beta_k X_{k}.  $$\n",
    "\n",
    "\n",
    "Por lo tanto, manteniendo todo lo demás constante, se puede estimar el cambio que una unidad extra en $X_1$ tiene sobre  el chance (o el *log-odds*) $log\\frac{p(Y_i)}{1-p(Y_i)}$. Esta estimación está dada por $\\hat \\beta_1$. \n",
    "\n",
    "\n",
    "Los coeficientes del modelo se pueden estimar por el método de máxima verosimilitud, buscando iterativamente estimadores que maximicen la función de verosimilitud: $$ F_{\\mathbf{\\beta}}=\\prod_{i:Y_i=1} p(Y_i)\\prod_{i':Y_{i'}=0}(1-p(Y_{i'})). $$\n",
    "\n",
    "\n",
    "Finalmente, la extensión del modelo logístico para múltiples clases o categorías ($C$) se hace calculando la probabilidad de una categoría ($C_i$) frente al resto y utilizando lo que se conoce como una función *softmax*: \n",
    "$$ \\sigma (Z_i )={\\frac {e^{Z_{i}}}{\\sum _{j=1}^{|C|}e^{Z_{j}}}}{\\text{ para }}i=1,\\dotsc ,|C|$$\n",
    "\n",
    "\n",
    "Miremos un ejemplo con nuestros datos sobre el comportamiento de los clientes del banco. Primero descargamos los paquetes que vamos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, la funcion `LogisticRegression()` encuentra una solución mediante el algoritmo de Broyden–Fletcher–Goldfarb–Shanno (BFGS):  https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.53490795e-02  8.32828686e-05  2.22994872e-01 -7.13817545e-02\n",
      "  -2.22146556e-02  7.39686688e-02 -7.03973050e-02  7.03443103e-01\n",
      "   2.88496336e-01 -1.22332415e-01 -1.09933253e+00  2.88107441e-01\n",
      "   2.65242607e-01 -2.08780273e-01  8.05932574e-03 -5.82354611e-01\n",
      "   5.51407204e-01 -5.29589072e-01 -3.58563564e-02 -1.38025358e-01\n",
      "  -3.87137718e-01  1.13642985e-02  7.80704681e-02  2.10294400e-01\n",
      "  -4.70498965e-02  5.67965193e-02  4.24302065e-01  7.78439695e-02\n",
      "  -9.25894173e-02 -1.83170264e-01 -4.56111864e-01  5.11704084e-02\n",
      "   1.64827883e-01  2.68686548e-02 -4.49632259e-01 -2.29601981e-02\n",
      "   1.52344342e-01  8.95904419e-02 -3.78968299e-01 -9.26919962e-02\n",
      "  -4.47814676e-02  9.41959683e-02 -2.79140011e-01 -3.74201999e-01\n",
      "  -6.28300432e-02  2.92406727e-02  1.78065859e-01  2.10800120e-01\n",
      "   9.93048498e-02 -5.39830481e-01  7.49756220e-02 -3.19945599e-01\n",
      "   1.52444666e-02 -1.82715024e-02 -7.36578039e-02 -6.29687773e-02\n",
      "  -7.48274270e-02  1.83586723e-02 -2.48084183e-01 -1.17063934e-03\n",
      "  -2.28554871e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerson.guerrero/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(max_iter=100)\n",
    "log.fit(X, Y)\n",
    "y_pred_log = log.predict(X)\n",
    "log_coef = log.coef_\n",
    "print(log_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1\n",
    "\n",
    "Ajuste las opciones de la funcion `LogisticRegression`para conseguir que la solucion converja. Puede examinar la documentación de Python: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un cambio en el método de convergencia a _newton-cg_ (Newton Conjugate Gradient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.77541715e-02  1.21598920e-04  3.19443685e-01  6.65859716e-03\n",
      "  -1.42821979e-02  2.45671110e-01  2.33713161e-01  7.38105633e-01\n",
      "   3.67668695e-01 -1.85310100e-01 -9.20534543e-01  4.90882969e-01\n",
      "   5.96389805e-01 -1.91718234e-02 -2.45440543e-01 -8.22730724e-01\n",
      "   7.20231004e-01 -8.18934978e-01 -4.58246344e-01 -2.60422884e-02\n",
      "  -1.40592421e-01  1.51191591e-01  4.17429792e-01  6.88360305e-01\n",
      "  -5.65700017e-01  3.22330412e-02  5.63734978e-01  2.26835349e-01\n",
      "   1.48066454e-01 -5.83139751e-01 -3.55567346e-01  2.13897540e-01\n",
      "   2.18293361e-01  9.53667826e-02 -5.18386687e-01 -9.24131201e-03\n",
      "   3.36140234e-01  1.02992922e-01 -4.15275975e-01 -2.39274963e-02\n",
      "   1.73625908e-01  5.06717403e-01 -6.80413626e-01 -2.81545269e-01\n",
      "  -1.29754302e-02 -8.38730534e-02  3.78323437e-01  2.38151205e-01\n",
      "   1.36697396e-01 -3.74918917e-01  3.31401098e-01 -9.09808681e-02\n",
      "  -2.40490546e-01 -2.53674847e-01  8.80771130e-02  1.17421938e-01\n",
      "   4.81054808e-02  1.45226598e-01 -1.45296914e-01  5.83463476e-01\n",
      "  -5.83533791e-01]]\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(solver=\"newton-cg\", max_iter=100) \n",
    "log.fit(X, Y)\n",
    "y_pred_log = log.predict(X)\n",
    "log_coef = log.coef_\n",
    "print(log_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3.2 \n",
    "\n",
    "Cuántas iteraciones necesitó?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método de _newton-cg_, la regresión converge con 60 iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construccion de modelos predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos los datos de manera aleatoria en un conjunto de entrenamiento y otro de prueba. De esta manera, estimamos los coeficientes sobre los datos de entrenamiento, y ese mismo modelo lo probamos sobre los datos de prueba con el fin de controlar que el modelo esté generalizando bien y no se sobreajuste a los datos.\n",
    "\n",
    "A continuación ejecutamos el codigo para obtener una partición con el 40% de los datos en el conjunto de prueba. Nótese que por defecto la funcion `train_test_split` sigue una partición estratificada, es decir, mantiene la distribución inicial de las clases en ambos conjuntos de entrenamiento y prueba:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de CE, CP:  (600,) (400,)\n",
      "Observaciones de la clase positiva en entrenamiento: 182 y en prueba: 118\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "print(\"Tamaño de CE, CP: \", y_train.shape, y_test.shape)\n",
    "print(\"Observaciones de la clase positiva en entrenamiento: \" +str(sum(y_train)) +\" y en prueba: \" +str(sum(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo podemos verificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de CE, CP:  (600,) (400,)\n",
      "Observaciones de la clase positiva en entrenamiento: 180 y en prueba: 120\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.4, random_state=42, stratify=Y)\n",
    "print(\"Tamaño de CE, CP: \", y_train.shape, y_test.shape)\n",
    "print(\"Observaciones de la clase positiva en entrenamiento: \" +str(sum(y_train)) +\" y en prueba: \" +str(sum(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación ajustamos el modelo logístico y lo probamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logT = LogisticRegression(penalty='none', max_iter=1500)\n",
    "logT.fit(X_train, y_train)\n",
    "y_tr = logT.predict(X_train)\n",
    "y_pred = logT.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con menos datos para entrenar probablemente el algoritmo necesite más iteraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([375], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logT.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinemos los coeficientes del modelo y su desviación con respecto a la estimación anterior (que utilizaba todos los datos de la muestra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.10773005e-02  1.02771308e-04  3.15481725e-01  1.79826321e-02\n",
      "  -8.12310264e-03  1.50526022e-01  7.30169441e-02  5.64754573e-01\n",
      "   1.26136252e-01 -2.83119926e-01 -9.67068789e-01  3.66444227e-01\n",
      "   2.94985173e-01 -1.43018240e-01  1.13700582e-01 -1.19140963e+00\n",
      "   2.21176769e-01 -8.44727770e-01 -2.85274400e-01 -3.87568911e-01\n",
      "  -2.91246871e-01 -3.87054885e-02  1.53002248e-01  7.29406448e-01\n",
      "  -1.80227159e-03  1.86442359e-01  5.97861031e-01  2.17654985e-01\n",
      "  -2.48653168e-01 -7.34607230e-01 -3.91553507e-01  5.02533398e-01\n",
      "   1.34453717e-01 -1.10384580e-02 -1.11518636e+00 -7.00601867e-02\n",
      "   3.00665101e-01 -1.73532620e-01 -5.70567006e-01 -1.15863364e-01\n",
      "  -1.96750670e-01  2.24357306e-01 -5.86904525e-01 -4.77452082e-01\n",
      "  -5.29445374e-02 -1.08602042e-01  7.97007722e-02  1.03176798e-01\n",
      "   1.17743856e-01 -7.80218543e-01  4.20012509e-01 -4.49166502e-01\n",
      "  -5.30143896e-01 -3.18330326e-02 -1.00369546e-01 -8.30431900e-02\n",
      "  -3.44052120e-01 -1.36532853e-01 -4.22765036e-01  2.48149325e-01\n",
      "  -8.07447214e-01]]\n"
     ]
    }
   ],
   "source": [
    "logT_coef = logT.coef_\n",
    "print(logT_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.67687101e-03  1.88276115e-05  3.96195954e-03 -1.13240350e-02\n",
      "  -6.15909523e-03  9.51450876e-02  1.60696217e-01  1.73351059e-01\n",
      "   2.41532443e-01  9.78098254e-02  4.65342458e-02  1.24438742e-01\n",
      "   3.01404632e-01  1.23846416e-01 -3.59141125e-01  3.68678908e-01\n",
      "   4.99054235e-01  2.57927923e-02 -1.72971944e-01  3.61526623e-01\n",
      "   1.50654449e-01  1.89897080e-01  2.64427544e-01 -4.10461425e-02\n",
      "  -5.63897745e-01 -1.54209317e-01 -3.41260525e-02  9.18036403e-03\n",
      "   3.96719622e-01  1.51467479e-01  3.59861607e-02 -2.88635858e-01\n",
      "   8.38396441e-02  1.06405241e-01  5.96799672e-01  6.08188747e-02\n",
      "   3.54751329e-02  2.76525542e-01  1.55291031e-01  9.19358680e-02\n",
      "   3.70376578e-01  2.82360097e-01 -9.35091012e-02  1.95906813e-01\n",
      "   3.99691072e-02  2.47289886e-02  2.98622665e-01  1.34974408e-01\n",
      "   1.89535397e-02  4.05299626e-01 -8.86114101e-02  3.58185634e-01\n",
      "   2.89653350e-01 -2.21841814e-01  1.88446659e-01  2.00465128e-01\n",
      "   3.92157601e-01  2.81759451e-01  2.77468122e-01  3.35314151e-01\n",
      "   2.23913423e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(log_coef-logT_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4.1\n",
    "\n",
    "Implemente un proceso de validación cruzada cambiando la semilla de las particiones de train (CE) y test (CP). Estimae la varianza de los estimadores y concluya si su *mejor* modelo es estable entre distintas particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_cv=[]\n",
    "random_states = [43, 12, 56, 32, 71, 73, 47, 18, 24, 19]\n",
    "\n",
    "for seed in random_states:\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.4, random_state=seed)\n",
    "    log_cv = LogisticRegressionCV(max_iter=3500, cv=5, random_state=seed)#, solver='newton-cg')\n",
    "    log_cv.fit(X_train, y_train)\n",
    "    lista=log_cv.coef_\n",
    "    flattened = [val for sublist in lista for val in sublist]\n",
    "    coef_cv.append(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se convierten los diferentes coeficientes generados por cada iteración en un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.193961</td>\n",
       "      <td>-0.025652</td>\n",
       "      <td>-0.029435</td>\n",
       "      <td>0.083539</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>0.370676</td>\n",
       "      <td>0.215577</td>\n",
       "      <td>-0.058462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237188</td>\n",
       "      <td>0.157446</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.052285</td>\n",
       "      <td>-0.041904</td>\n",
       "      <td>0.047121</td>\n",
       "      <td>0.076275</td>\n",
       "      <td>-0.123519</td>\n",
       "      <td>0.054529</td>\n",
       "      <td>-0.101773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.150371</td>\n",
       "      <td>-0.007689</td>\n",
       "      <td>-0.009195</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>0.324972</td>\n",
       "      <td>0.231364</td>\n",
       "      <td>-0.005570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203564</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>-0.058645</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.007050</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>-0.067985</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>-0.075463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028211</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.074683</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>-0.027575</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.127459</td>\n",
       "      <td>0.058789</td>\n",
       "      <td>-0.014969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015085</td>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>-0.006137</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>-0.031122</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>-0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027416</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.256634</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.105665</td>\n",
       "      <td>0.103281</td>\n",
       "      <td>0.658725</td>\n",
       "      <td>0.282622</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522282</td>\n",
       "      <td>0.049590</td>\n",
       "      <td>0.160462</td>\n",
       "      <td>-0.136283</td>\n",
       "      <td>-0.014648</td>\n",
       "      <td>-0.220108</td>\n",
       "      <td>0.180473</td>\n",
       "      <td>-0.391051</td>\n",
       "      <td>0.105148</td>\n",
       "      <td>-0.315726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024721</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.316414</td>\n",
       "      <td>0.090735</td>\n",
       "      <td>-0.005285</td>\n",
       "      <td>0.037841</td>\n",
       "      <td>0.081012</td>\n",
       "      <td>0.544477</td>\n",
       "      <td>0.102231</td>\n",
       "      <td>-0.121925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255467</td>\n",
       "      <td>-0.161235</td>\n",
       "      <td>0.049767</td>\n",
       "      <td>-0.181790</td>\n",
       "      <td>-0.257493</td>\n",
       "      <td>0.120206</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>-0.324314</td>\n",
       "      <td>0.258504</td>\n",
       "      <td>-0.527813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.022686</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.237550</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>-0.010659</td>\n",
       "      <td>-0.078621</td>\n",
       "      <td>0.059714</td>\n",
       "      <td>0.491019</td>\n",
       "      <td>0.232403</td>\n",
       "      <td>-0.091901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411805</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>-0.017696</td>\n",
       "      <td>-0.083584</td>\n",
       "      <td>-0.006142</td>\n",
       "      <td>-0.041670</td>\n",
       "      <td>0.060360</td>\n",
       "      <td>-0.209452</td>\n",
       "      <td>0.237235</td>\n",
       "      <td>-0.386327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.035545</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.222275</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.002737</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>0.206038</td>\n",
       "      <td>0.754294</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>-0.074459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394834</td>\n",
       "      <td>0.121537</td>\n",
       "      <td>-0.156455</td>\n",
       "      <td>0.110553</td>\n",
       "      <td>-0.216781</td>\n",
       "      <td>0.084954</td>\n",
       "      <td>-0.126215</td>\n",
       "      <td>-0.051515</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>-0.346076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037144</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.197983</td>\n",
       "      <td>-0.050814</td>\n",
       "      <td>-0.020472</td>\n",
       "      <td>0.053905</td>\n",
       "      <td>0.209541</td>\n",
       "      <td>0.652470</td>\n",
       "      <td>0.390548</td>\n",
       "      <td>-0.164432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243660</td>\n",
       "      <td>-0.107634</td>\n",
       "      <td>-0.121575</td>\n",
       "      <td>-0.035868</td>\n",
       "      <td>-0.005736</td>\n",
       "      <td>-0.011278</td>\n",
       "      <td>0.044917</td>\n",
       "      <td>-0.219374</td>\n",
       "      <td>0.129971</td>\n",
       "      <td>-0.304428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.299779</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>-0.014560</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>0.395484</td>\n",
       "      <td>0.680059</td>\n",
       "      <td>0.113037</td>\n",
       "      <td>-0.125455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184593</td>\n",
       "      <td>-0.221245</td>\n",
       "      <td>-0.148140</td>\n",
       "      <td>-0.204136</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>0.146436</td>\n",
       "      <td>-0.078905</td>\n",
       "      <td>-0.307723</td>\n",
       "      <td>0.314323</td>\n",
       "      <td>-0.700951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.036918</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.164685</td>\n",
       "      <td>-0.065809</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.140370</td>\n",
       "      <td>-0.093081</td>\n",
       "      <td>0.662591</td>\n",
       "      <td>0.172303</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207115</td>\n",
       "      <td>0.069456</td>\n",
       "      <td>-0.039019</td>\n",
       "      <td>-0.055415</td>\n",
       "      <td>0.016372</td>\n",
       "      <td>-0.105249</td>\n",
       "      <td>-0.010816</td>\n",
       "      <td>-0.172495</td>\n",
       "      <td>0.174308</td>\n",
       "      <td>-0.357619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "3  0.030838  0.000089  0.193961 -0.025652 -0.029435  0.083539 -0.002745   \n",
       "2  0.028889  0.000047  0.150371 -0.007689 -0.009195  0.012114  0.024949   \n",
       "5  0.028211  0.000039  0.074683  0.053966 -0.027575  0.014395  0.002814   \n",
       "1  0.027416  0.000084  0.256634  0.014117 -0.006089 -0.105665  0.103281   \n",
       "6  0.024721  0.000133  0.316414  0.090735 -0.005285  0.037841  0.081012   \n",
       "7  0.022686  0.000066  0.237550  0.038507 -0.010659 -0.078621  0.059714   \n",
       "8  0.035545  0.000035  0.222275  0.000027 -0.002737  0.011826  0.206038   \n",
       "4  0.037144  0.000041  0.197983 -0.050814 -0.020472  0.053905  0.209541   \n",
       "0  0.037761  0.000084  0.299779  0.036120 -0.014560  0.020965  0.395484   \n",
       "9  0.036918  0.000052  0.164685 -0.065809 -0.013694  0.140370 -0.093081   \n",
       "\n",
       "         7         8         9   ...        51        52        53        54  \\\n",
       "3  0.370676  0.215577 -0.058462  ... -0.237188  0.157446 -0.000176 -0.052285   \n",
       "2  0.324972  0.231364 -0.005570  ... -0.203564  0.017305  0.012014 -0.058645   \n",
       "5  0.127459  0.058789 -0.014969  ... -0.015085 -0.008194 -0.004336  0.007865   \n",
       "1  0.658725  0.282622 -0.279226  ... -0.522282  0.049590  0.160462 -0.136283   \n",
       "6  0.544477  0.102231 -0.121925  ... -0.255467 -0.161235  0.049767 -0.181790   \n",
       "7  0.491019  0.232403 -0.091901  ... -0.411805  0.026960 -0.017696 -0.083584   \n",
       "8  0.754294  0.035454 -0.074459  ... -0.394834  0.121537 -0.156455  0.110553   \n",
       "4  0.652470  0.390548 -0.164432  ... -0.243660 -0.107634 -0.121575 -0.035868   \n",
       "0  0.680059  0.113037 -0.125455  ... -0.184593 -0.221245 -0.148140 -0.204136   \n",
       "9  0.662591  0.172303  0.013673  ... -0.207115  0.069456 -0.039019 -0.055415   \n",
       "\n",
       "         55        56        57        58        59        60  \n",
       "3 -0.041904  0.047121  0.076275 -0.123519  0.054529 -0.101773  \n",
       "2  0.002519 -0.007050  0.016823 -0.067985  0.024300 -0.075463  \n",
       "5 -0.005745 -0.006137  0.022769 -0.031122  0.000734 -0.009087  \n",
       "1 -0.014648 -0.220108  0.180473 -0.391051  0.105148 -0.315726  \n",
       "6 -0.257493  0.120206  0.055004 -0.324314  0.258504 -0.527813  \n",
       "7 -0.006142 -0.041670  0.060360 -0.209452  0.237235 -0.386327  \n",
       "8 -0.216781  0.084954 -0.126215 -0.051515  0.168346 -0.346076  \n",
       "4 -0.005736 -0.011278  0.044917 -0.219374  0.129971 -0.304428  \n",
       "0 -0.180788  0.146436 -0.078905 -0.307723  0.314323 -0.700951  \n",
       "9  0.016372 -0.105249 -0.010816 -0.172495  0.174308 -0.357619  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coef = pd.DataFrame(coef_cv)\n",
    "data_coef.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el calculo de la varianza para determinar si efectivamente el modelo es estable ante distinos sets de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3.030970e-05\n",
       "1     9.467184e-10\n",
       "2     5.196605e-03\n",
       "3     2.340489e-03\n",
       "4     8.493893e-05\n",
       "          ...     \n",
       "56    1.186681e-02\n",
       "57    7.150703e-03\n",
       "58    1.528840e-02\n",
       "59    1.075717e-02\n",
       "60    4.428833e-02\n",
       "Length: 61, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coef.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01932869977404604"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coef.var(axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando Folds y modificando el solver al planteado inicialmente y utilizar menos iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Semillas controladas\n",
    "random_states = [43, 12, 56, 32, 71, 73, 47, 18, 24, 19]\n",
    "i=0\n",
    "coef = [];flattened=[]\n",
    "for seed in random_states:\n",
    "    log = LogisticRegression(solver=\"newton-cg\", max_iter=100)\n",
    "    kf = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(credit_1):\n",
    "        X_train = credit_1.iloc[train_index].iloc[:,1:62]\n",
    "        X_test = credit_1.iloc[test_index].iloc[:,1:62]\n",
    "        y_train = credit_1.iloc[train_index]['Default']\n",
    "        y_test = credit_1.iloc[test_index]['Default']\n",
    "\n",
    "        log.fit(X_train, y_train) #Training the model\n",
    "        flattened.append(log_cv.coef_)\n",
    "        flattened = [val for sublist in lista for val in sublist]\n",
    "        coef.append(flattened)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037144</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.197983</td>\n",
       "      <td>-0.050814</td>\n",
       "      <td>-0.020472</td>\n",
       "      <td>0.053905</td>\n",
       "      <td>0.209541</td>\n",
       "      <td>0.652470</td>\n",
       "      <td>0.390548</td>\n",
       "      <td>-0.164432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243660</td>\n",
       "      <td>-0.107634</td>\n",
       "      <td>-0.121575</td>\n",
       "      <td>-0.035868</td>\n",
       "      <td>-0.005736</td>\n",
       "      <td>-0.011278</td>\n",
       "      <td>0.044917</td>\n",
       "      <td>-0.219374</td>\n",
       "      <td>0.129971</td>\n",
       "      <td>-0.304428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.150371</td>\n",
       "      <td>-0.007689</td>\n",
       "      <td>-0.009195</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>0.324972</td>\n",
       "      <td>0.231364</td>\n",
       "      <td>-0.005570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203564</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>-0.058645</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.007050</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>-0.067985</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>-0.075463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027416</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.256634</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.105665</td>\n",
       "      <td>0.103281</td>\n",
       "      <td>0.658725</td>\n",
       "      <td>0.282622</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522282</td>\n",
       "      <td>0.049590</td>\n",
       "      <td>0.160462</td>\n",
       "      <td>-0.136283</td>\n",
       "      <td>-0.014648</td>\n",
       "      <td>-0.220108</td>\n",
       "      <td>0.180473</td>\n",
       "      <td>-0.391051</td>\n",
       "      <td>0.105148</td>\n",
       "      <td>-0.315726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.193961</td>\n",
       "      <td>-0.025652</td>\n",
       "      <td>-0.029435</td>\n",
       "      <td>0.083539</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>0.370676</td>\n",
       "      <td>0.215577</td>\n",
       "      <td>-0.058462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237188</td>\n",
       "      <td>0.157446</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.052285</td>\n",
       "      <td>-0.041904</td>\n",
       "      <td>0.047121</td>\n",
       "      <td>0.076275</td>\n",
       "      <td>-0.123519</td>\n",
       "      <td>0.054529</td>\n",
       "      <td>-0.101773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024721</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.316414</td>\n",
       "      <td>0.090735</td>\n",
       "      <td>-0.005285</td>\n",
       "      <td>0.037841</td>\n",
       "      <td>0.081012</td>\n",
       "      <td>0.544477</td>\n",
       "      <td>0.102231</td>\n",
       "      <td>-0.121925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255467</td>\n",
       "      <td>-0.161235</td>\n",
       "      <td>0.049767</td>\n",
       "      <td>-0.181790</td>\n",
       "      <td>-0.257493</td>\n",
       "      <td>0.120206</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>-0.324314</td>\n",
       "      <td>0.258504</td>\n",
       "      <td>-0.527813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.299779</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>-0.014560</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>0.395484</td>\n",
       "      <td>0.680059</td>\n",
       "      <td>0.113037</td>\n",
       "      <td>-0.125455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184593</td>\n",
       "      <td>-0.221245</td>\n",
       "      <td>-0.148140</td>\n",
       "      <td>-0.204136</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>0.146436</td>\n",
       "      <td>-0.078905</td>\n",
       "      <td>-0.307723</td>\n",
       "      <td>0.314323</td>\n",
       "      <td>-0.700951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.022686</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.237550</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>-0.010659</td>\n",
       "      <td>-0.078621</td>\n",
       "      <td>0.059714</td>\n",
       "      <td>0.491019</td>\n",
       "      <td>0.232403</td>\n",
       "      <td>-0.091901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411805</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>-0.017696</td>\n",
       "      <td>-0.083584</td>\n",
       "      <td>-0.006142</td>\n",
       "      <td>-0.041670</td>\n",
       "      <td>0.060360</td>\n",
       "      <td>-0.209452</td>\n",
       "      <td>0.237235</td>\n",
       "      <td>-0.386327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028211</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.074683</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>-0.027575</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.127459</td>\n",
       "      <td>0.058789</td>\n",
       "      <td>-0.014969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015085</td>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>-0.006137</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>-0.031122</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>-0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.036918</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.164685</td>\n",
       "      <td>-0.065809</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.140370</td>\n",
       "      <td>-0.093081</td>\n",
       "      <td>0.662591</td>\n",
       "      <td>0.172303</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207115</td>\n",
       "      <td>0.069456</td>\n",
       "      <td>-0.039019</td>\n",
       "      <td>-0.055415</td>\n",
       "      <td>0.016372</td>\n",
       "      <td>-0.105249</td>\n",
       "      <td>-0.010816</td>\n",
       "      <td>-0.172495</td>\n",
       "      <td>0.174308</td>\n",
       "      <td>-0.357619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.035545</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.222275</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.002737</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>0.206038</td>\n",
       "      <td>0.754294</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>-0.074459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394834</td>\n",
       "      <td>0.121537</td>\n",
       "      <td>-0.156455</td>\n",
       "      <td>0.110553</td>\n",
       "      <td>-0.216781</td>\n",
       "      <td>0.084954</td>\n",
       "      <td>-0.126215</td>\n",
       "      <td>-0.051515</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>-0.346076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "4  0.037144  0.000041  0.197983 -0.050814 -0.020472  0.053905  0.209541   \n",
       "2  0.028889  0.000047  0.150371 -0.007689 -0.009195  0.012114  0.024949   \n",
       "1  0.027416  0.000084  0.256634  0.014117 -0.006089 -0.105665  0.103281   \n",
       "3  0.030838  0.000089  0.193961 -0.025652 -0.029435  0.083539 -0.002745   \n",
       "6  0.024721  0.000133  0.316414  0.090735 -0.005285  0.037841  0.081012   \n",
       "0  0.037761  0.000084  0.299779  0.036120 -0.014560  0.020965  0.395484   \n",
       "7  0.022686  0.000066  0.237550  0.038507 -0.010659 -0.078621  0.059714   \n",
       "5  0.028211  0.000039  0.074683  0.053966 -0.027575  0.014395  0.002814   \n",
       "9  0.036918  0.000052  0.164685 -0.065809 -0.013694  0.140370 -0.093081   \n",
       "8  0.035545  0.000035  0.222275  0.000027 -0.002737  0.011826  0.206038   \n",
       "\n",
       "         7         8         9   ...        51        52        53        54  \\\n",
       "4  0.652470  0.390548 -0.164432  ... -0.243660 -0.107634 -0.121575 -0.035868   \n",
       "2  0.324972  0.231364 -0.005570  ... -0.203564  0.017305  0.012014 -0.058645   \n",
       "1  0.658725  0.282622 -0.279226  ... -0.522282  0.049590  0.160462 -0.136283   \n",
       "3  0.370676  0.215577 -0.058462  ... -0.237188  0.157446 -0.000176 -0.052285   \n",
       "6  0.544477  0.102231 -0.121925  ... -0.255467 -0.161235  0.049767 -0.181790   \n",
       "0  0.680059  0.113037 -0.125455  ... -0.184593 -0.221245 -0.148140 -0.204136   \n",
       "7  0.491019  0.232403 -0.091901  ... -0.411805  0.026960 -0.017696 -0.083584   \n",
       "5  0.127459  0.058789 -0.014969  ... -0.015085 -0.008194 -0.004336  0.007865   \n",
       "9  0.662591  0.172303  0.013673  ... -0.207115  0.069456 -0.039019 -0.055415   \n",
       "8  0.754294  0.035454 -0.074459  ... -0.394834  0.121537 -0.156455  0.110553   \n",
       "\n",
       "         55        56        57        58        59        60  \n",
       "4 -0.005736 -0.011278  0.044917 -0.219374  0.129971 -0.304428  \n",
       "2  0.002519 -0.007050  0.016823 -0.067985  0.024300 -0.075463  \n",
       "1 -0.014648 -0.220108  0.180473 -0.391051  0.105148 -0.315726  \n",
       "3 -0.041904  0.047121  0.076275 -0.123519  0.054529 -0.101773  \n",
       "6 -0.257493  0.120206  0.055004 -0.324314  0.258504 -0.527813  \n",
       "0 -0.180788  0.146436 -0.078905 -0.307723  0.314323 -0.700951  \n",
       "7 -0.006142 -0.041670  0.060360 -0.209452  0.237235 -0.386327  \n",
       "5 -0.005745 -0.006137  0.022769 -0.031122  0.000734 -0.009087  \n",
       "9  0.016372 -0.105249 -0.010816 -0.172495  0.174308 -0.357619  \n",
       "8 -0.216781  0.084954 -0.126215 -0.051515  0.168346 -0.346076  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coef = pd.DataFrame(coef_cv)\n",
    "data_coef.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3.030970e-05\n",
       "1     9.467184e-10\n",
       "2     5.196605e-03\n",
       "3     2.340489e-03\n",
       "4     8.493893e-05\n",
       "          ...     \n",
       "56    1.186681e-02\n",
       "57    7.150703e-03\n",
       "58    1.528840e-02\n",
       "59    1.075717e-02\n",
       "60    4.428833e-02\n",
       "Length: 61, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coef.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01932869977404604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coef.var(axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluacion de los modelos\n",
    "Hasta ahora hemos estimado los parámetros del modelo logístico. Pero no hemos examinado si la solución es satisfactoria. A continuación examinemos el desempeño de los modelos a partir de su matriz de confusión: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242  38]\n",
      " [ 58  62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculamos la matriz de confusión para la prediccion\n",
    "cm_log = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print(cm_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos mejorar esta visualización, añadiendo etiquetas para lo que es predicción y lo que es observado en la muestra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Matriz de confusión', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta verdadera')\n",
    "    plt.xlabel('Etiqueta estimada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels=['Bueno (Default=0)' ,'Malo (Default=1)']\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos resumir estos resultados, por ejemplo mediante la métrica de *exactitud* o *accuracy*, la cual mide la proporción de aciertos sobre el total de casos.\n",
    "\n",
    "Para entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float((y_tr == y_train).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float((y_pred == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5.1\n",
    "\n",
    "Calcule una métrica de desempeño que tome en cuenta el coste de errar, donde el coste de predecir que un mal cliente es bueno es 5 veces más alto que el de confundir un buen cliente con uno malo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la matriz de confusión para la prediccion en entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(solver=\"newton-cg\", max_iter=100)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.4, random_state=42, stratify=Y)\n",
    "log.fit(X_train, y_train)\n",
    "y_tr = log.predict(X_train)\n",
    "y_pred = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_log_tr = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print(cm_log_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "VP = cm_log_tr[0][0];FN=cm_log_tr[0][1]\n",
    "VN = cm_log_tr[1][1];FP=cm_log_tr[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la métrica de la precisión el modelo actual nos arroja una precisión de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision = {(VP+VN)/(VP+VN+FN+FP)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, dada la importancia que tiene no generar falsos positivos (predecir que es No es default dado que si lo es), nos interesa una métrica que nos relacione los Falos Positivos o los Verdaderos Negativos. En ese caso, si calculamos la especificidad, que es un score que nos resalta la relación de los Verdaderos Negativos nos arroja _*0.51*_ lo cual es aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Especificidad = 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"Especificidad = {VN/(VN+FP)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le agregamos el componente x5 directamente a la precisión, para desbalancear la ecuación e indicar que los _FN_ son cinco veces más relevantes nos entregaría un valor aproximado al anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La métrica calculada añadiendole un peso x5 sobre los falsos positivos sería: 0.4810126582278481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m_tr=(VP+VN)/(VP+VN+FN+5*FP)\n",
    "\n",
    "print(f\"La métrica calculada añadiendole un peso x5 sobre los falsos positivos sería: {m_tr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elige alta Especificidad:  si se desea identificar los verdaderos negativos, o lo que es igual cuando no desea falsos positivos. Realizamos un pequeño ajuste sobre los parámetros del modelo para tener una mejor especificidad. En el parámetro _class_weight_ se especifica un _dict_ con los pesos que se desean sobre los valores del _target_ para balancear el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.66\n",
      "Especificidad = 0.85\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(solver=\"newton-cg\", max_iter=100, class_weight={1:0.8,0:0.2})\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.4, random_state=42, stratify=Y)\n",
    "log.fit(X_train, y_train)\n",
    "y_tr = log.predict(X_train)\n",
    "y_pred = log.predict(X_test)\n",
    "cm_log_tr = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "VP = cm_log_tr[0][0];FN=cm_log_tr[0][1]\n",
    "VN = cm_log_tr[1][1];FP=cm_log_tr[1][0]\n",
    "print(f\"Precision = {(VP+VN)/(VP+VN+FN+FP)}\")\n",
    "print(f\"Especificidad = {VN/(VN+FP)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   default=0       0.90      0.58      0.70       280\n",
      "   default=1       0.46      0.85      0.60       120\n",
      "\n",
      "    accuracy                           0.66       400\n",
      "   macro avg       0.68      0.71      0.65       400\n",
      "weighted avg       0.77      0.66      0.67       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=[\"default=0\",\"default=1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justicia algorítmica\n",
    "\n",
    "Veamos cómo se comporta el modelo de acuerdo con el origen (extranjero o local) del cliente. Por ejemplo, fijémonos en el balance inicial de los datos de la muestra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_2 = credit_1.copy()\n",
    "credit_3 = credit_2.loc[credit_2['foreign_A201'] == 1]\n",
    "X3 = credit_3.iloc[:, 1:62]\n",
    "Y3 = credit_3.iloc[:, 0]\n",
    "\n",
    "credit_4 = credit_2.loc[credit_2['foreign_A201'] == 0]\n",
    "X4 = credit_4.iloc[:, 1:62]\n",
    "Y4 = credit_4.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de clientes extranjeros de la muestra: 963 y los locales: 37\n"
     ]
    }
   ],
   "source": [
    "print(\"El numero de clientes extranjeros de la muestra: \" +str(X3.shape[0]) +\" y los locales: \" +str(X4.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 5.2\n",
    "\n",
    "De los clientes locales cuantos han tenido Default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Default</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreign_A201</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>667</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Default         0    1\n",
       "foreign_A201          \n",
       "0              33    4\n",
       "1             667  296"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross=pd.crosstab(credit_2['foreign_A201'],Y)\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes locales con default: 4\n"
     ]
    }
   ],
   "source": [
    "N_Local_Default = credit_1.loc[(credit_1['foreign_A201'] ==0) & (credit_1['Default'] == 1)].shape[0]\n",
    "print(f\"Clientes locales con default: {N_Local_Default}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ya hay un sesgo en los datos de entrenamiento. Por lo tanto, podemos esperar que esto se vea reflejado en nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = logT.predict(X3)\n",
    "y_pred_l = logT.predict(X4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos otra manera de visualizar la matriz de confusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extranjeros:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locales:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "print(\"Extranjeros:\")\n",
    "plot_confusion_matrix(logT, X3, Y3, normalize='all')  \n",
    "plt.show() \n",
    "\n",
    "print(\"Locales:\")\n",
    "plot_confusion_matrix(logT, X4, Y4, normalize='all')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y las métricas de exactitud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud para el usuario extranjero: 0.7684319833852544\n",
      "La exactitud para el usuario local: 0.9459459459459459\n"
     ]
    }
   ],
   "source": [
    "print(\"La exactitud para el usuario extranjero:\", float((y_pred_f == Y3).mean()))\n",
    "print(\"La exactitud para el usuario local:\", float((y_pred_l == Y4).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5.3\n",
    "\n",
    "Proponga una modelo de clasificación que detecte clientes con un alto riesgo de Default, teniendo en cuenta el costo de clasificar a un cliente erroneamente  junto con la \"equidad algoritmica\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente realizamos un análisis para determinar si podemos descartar la variable que indica la nacionalidad, dado que se encuentra que el desbalance es muy grande y correríamos el riesgo de sobre ajustar el modelo por la generación de variables sinteticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447909\n",
      "         Iterations 21\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Default   No. Observations:                 1000\n",
      "Model:                          Logit   Df Residuals:                      951\n",
      "Method:                           MLE   Df Model:                           48\n",
      "Date:                Mon, 17 Aug 2020   Pseudo R-squ.:                  0.2668\n",
      "Time:                        15:48:06   Log-Likelihood:                -447.91\n",
      "converged:                       True   LL-Null:                       -610.86\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.755e-43\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "duration                0.0279      0.009      2.997      0.003       0.010       0.046\n",
      "amount                  0.0001   4.44e-05      2.887      0.004    4.12e-05       0.000\n",
      "installment             0.3301      0.088      3.739      0.000       0.157       0.503\n",
      "residence               0.0048      0.086      0.055      0.956      -0.165       0.174\n",
      "age                    -0.0145      0.009     -1.576      0.115      -0.033       0.004\n",
      "cards                   0.2721      0.190      1.436      0.151      -0.099       0.644\n",
      "liable                  0.2647      0.249      1.062      0.288      -0.224       0.753\n",
      "checkingstatus1_A11     5.3607        nan        nan        nan         nan         nan\n",
      "checkingstatus1_A12     4.9858        nan        nan        nan         nan         nan\n",
      "checkingstatus1_A13     4.3950        nan        nan        nan         nan         nan\n",
      "checkingstatus1_A14     3.6488        nan        nan        nan         nan         nan\n",
      "history_A30            -0.2075        nan        nan        nan         nan         nan\n",
      "history_A31            -0.0641        nan        nan        nan         nan         nan\n",
      "history_A32            -0.7936        nan        nan        nan         nan         nan\n",
      "history_A33            -1.0606        nan        nan        nan         nan         nan\n",
      "history_A34            -1.6432        nan        nan        nan         nan         nan\n",
      "purpose_A40             0.3490        nan        nan        nan         nan         nan\n",
      "purpose_A41            -1.3174        nan        nan        nan         nan         nan\n",
      "purpose_A410           -1.1397        nan        nan        nan         nan         nan\n",
      "purpose_A42            -0.4426        nan        nan        nan         nan         nan\n",
      "purpose_A43            -0.5425        nan        nan        nan         nan         nan\n",
      "purpose_A44            -0.1737        nan        nan        nan         nan         nan\n",
      "purpose_A45             0.1327        nan        nan        nan         nan         nan\n",
      "purpose_A46             0.3853        nan        nan        nan         nan         nan\n",
      "purpose_A48            -1.7104        nan        nan        nan         nan         nan\n",
      "purpose_A49            -0.3910        nan        nan        nan         nan         nan\n",
      "savings_A61            -2.4657   5.19e+06  -4.75e-07      1.000   -1.02e+07    1.02e+07\n",
      "savings_A62            -2.8234   5.01e+06  -5.64e-07      1.000   -9.82e+06    9.82e+06\n",
      "savings_A63            -2.8418   4.82e+06   -5.9e-07      1.000   -9.45e+06    9.45e+06\n",
      "savings_A64            -3.8049   4.72e+06  -8.07e-07      1.000   -9.24e+06    9.24e+06\n",
      "savings_A65            -3.4124   4.55e+06  -7.51e-07      1.000   -8.91e+06    8.91e+06\n",
      "employ_A71             -3.6949        nan        nan        nan         nan         nan\n",
      "employ_A72             -3.7618        nan        nan        nan         nan         nan\n",
      "employ_A73             -3.8777        nan        nan        nan         nan         nan\n",
      "employ_A74             -4.5259        nan        nan        nan         nan         nan\n",
      "employ_A75             -3.9715        nan        nan        nan         nan         nan\n",
      "status_A91             -3.7103   7.39e+06  -5.02e-07      1.000   -1.45e+07    1.45e+07\n",
      "status_A92             -3.9858   7.64e+06  -5.22e-07      1.000    -1.5e+07     1.5e+07\n",
      "status_A93             -4.5264   7.42e+06   -6.1e-07      1.000   -1.45e+07    1.45e+07\n",
      "status_A94             -4.0774   7.45e+06  -5.47e-07      1.000   -1.46e+07    1.46e+07\n",
      "others_A101             9.1487   2.94e+06   3.11e-06      1.000   -5.76e+06    5.76e+06\n",
      "others_A102             9.5847   2.92e+06   3.28e-06      1.000   -5.72e+06    5.72e+06\n",
      "others_A103             8.1701   3.02e+06   2.71e-06      1.000   -5.91e+06    5.91e+06\n",
      "property_A121          -0.0047   7.94e+06  -5.91e-10      1.000   -1.56e+07    1.56e+07\n",
      "property_A122           0.2767   7.82e+06   3.54e-08      1.000   -1.53e+07    1.53e+07\n",
      "property_A123           0.1898   8.39e+06   2.26e-08      1.000   -1.65e+07    1.65e+07\n",
      "property_A124           0.7258   8.08e+06   8.98e-08      1.000   -1.58e+07    1.58e+07\n",
      "otherplans_A141        -2.4568        nan        nan        nan         nan         nan\n",
      "otherplans_A142        -2.5800        nan        nan        nan         nan         nan\n",
      "otherplans_A143        -3.1032        nan        nan        nan         nan         nan\n",
      "housing_A151            1.5376        nan        nan        nan         nan         nan\n",
      "housing_A152            1.0940        nan        nan        nan         nan         nan\n",
      "housing_A153            0.8538   1.48e+06   5.77e-07      1.000    -2.9e+06     2.9e+06\n",
      "job_A171               -3.2347   3.64e+06  -8.88e-07      1.000   -7.14e+06    7.14e+06\n",
      "job_A172               -2.6986   3.62e+06  -7.46e-07      1.000   -7.09e+06    7.09e+06\n",
      "job_A173               -2.6800   3.68e+06  -7.27e-07      1.000   -7.22e+06    7.22e+06\n",
      "job_A174               -2.7553   3.56e+06  -7.75e-07      1.000   -6.97e+06    6.97e+06\n",
      "tele_A191              -0.3835        nan        nan        nan         nan         nan\n",
      "tele_A192              -0.6835        nan        nan        nan         nan         nan\n",
      "foreign_A201            0.1626   1.76e+06   9.23e-08      1.000   -3.45e+06    3.45e+06\n",
      "foreign_A202           -1.2296   1.76e+06  -6.98e-07      1.000   -3.45e+06    3.45e+06\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logit_model=sm.Logit(Y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que el campo foreign (A201 y A202) no son significativos por lo tanto no aporta mayor información al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = credit_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['foreign_A201', 'foreign_A202'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(solver=\"newton-cg\", max_iter=100, class_weight = {1:0.8,0:0.2})\n",
    "X = df.iloc[:, 1:60]\n",
    "Y = df.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.4, random_state=42, stratify=Y)\n",
    "log.fit(X_train, y_train)\n",
    "y_pred = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   default=0       0.90      0.57      0.70       280\n",
      "   default=1       0.46      0.85      0.60       120\n",
      "\n",
      "    accuracy                           0.66       400\n",
      "   macro avg       0.68      0.71      0.65       400\n",
      "weighted avg       0.77      0.66      0.67       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=[\"default=0\",\"default=1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a generar los datasets anteriores, para quitarles las columnas de _foreign_ y posterior determinar los resultados del modelo y comparar si se reduce el GAP entre las predicciones sobre extranjeros y locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_2_ = credit_1.copy()\n",
    "credit_3_ = credit_2_.loc[credit_2_['foreign_A201'] == 1]\n",
    "X3_ = credit_3_.iloc[:, 1:62]\n",
    "Y3_ = credit_3_.iloc[:, 0]\n",
    "\n",
    "credit_4_ = credit_2_.loc[credit_2_['foreign_A201'] == 0]\n",
    "X4_ = credit_4_.iloc[:, 1:62]\n",
    "Y4_ = credit_4_.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_ = X3_.drop(['foreign_A201', 'foreign_A202'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_ = X4_.drop(['foreign_A201', 'foreign_A202'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = log.predict(X3_)\n",
    "y_pred_l = log.predict(X4_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud para el usuario extranjero: 0.6812045690550363\n",
      "La exactitud para el usuario local: 0.7027027027027027\n"
     ]
    }
   ],
   "source": [
    "print(\"La exactitud para el usuario extranjero:\", float((y_pred_f == Y3_).mean()))\n",
    "print(\"La exactitud para el usuario local:\", float((y_pred_l == Y4_).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extranjeros:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locales:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "print(\"Extranjeros:\")\n",
    "plot_confusion_matrix(log, X3_, Y3_, normalize='all')  \n",
    "plt.show() \n",
    "\n",
    "print(\"Locales:\")\n",
    "plot_confusion_matrix(log, X4_, Y4_, normalize='all')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el GAP que existia para extranjeros y locales se reduce al no incluir la variable _foreign_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecturas avanzadas\n",
    "\n",
    "Para ler más sobre la ética algoritmica puede ver: Pessach, D., Shmueli, E. (2020) Algorithmic fairness. https://arxiv.org/abs/2001.09784 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
